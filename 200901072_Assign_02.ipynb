{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "51026117",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expression : \" {a -2/5*2} \"\n",
      "\n",
      "Expression after Spliting & Removing Whitesapces : \n",
      "\n",
      " ['{', 'a', '-', '2', '/', '5', '*', '2', '}']\n",
      "\n",
      "Expression after Tokenization : \n",
      "\n",
      " {'{': {'Punctuator'}, 'a': {'Identifier'}, '-': {'Operator'}, '2': {'Constant'}, '/': {'Operator'}, '5': {'Constant'}, '*': {'Operator'}, '}': {'Punctuator'}}\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "\n",
    "class lexical_analyzer:\n",
    "    \n",
    "    #constructor\n",
    "    def __init__(self, stringInput):\n",
    "        self.expression_Input = stringInput\n",
    "        self.listTokens = None\n",
    "        self.whiteSpace = ' '\n",
    "        self.listOperators = ['+', '*', '/']\n",
    "        self.varMinus = '-'\n",
    "        self.listPunctuators = ['{', '}', '(', ')']\n",
    "        self.special_characters = ['&', '%', '$']\n",
    "        self.tokenization_of_expression = {}\n",
    "    \n",
    "    # function to split the entered tokens and remove the whitespaces if there's any\n",
    "    def splitFunction(self):\n",
    "\n",
    "        self.listTokens = []\n",
    "        for token in self.expression_Input:\n",
    "            if token == self.whiteSpace:\n",
    "                continue\n",
    "            else:\n",
    "                self.listTokens.append(token)\n",
    "        print('\\nExpression after Spliting & Removing Whitesapces : \\n\\n', self.listTokens)\n",
    "    # function to print token before Tokenization\n",
    "   \n",
    "    def print_before_tokenization(self):\n",
    "        print('Expression : \\\"', self.expression_Input, '\\\"')\n",
    "        \n",
    "    # function to find the accurate category of all the elements in listTokens and store them in a dictionary \n",
    "    def tokenFinder(self):\n",
    "\n",
    "        for finder in self.listTokens:\n",
    "\n",
    "            if re.search('[a-zA-Z]', finder):\n",
    "                self.tokenization_of_expression[finder] = {'Identifier'}\n",
    "            elif re.search(f'{self.listOperators}', finder) or finder == self.varMinus:\n",
    "                self.tokenization_of_expression[finder] = {'Operator'}\n",
    "            elif re.search('[0-9]', finder) :\n",
    "                self.tokenization_of_expression[finder] = {'Constant'}\n",
    "            elif re.search(f'{self.listPunctuators}', finder):\n",
    "                self.tokenization_of_expression[finder] = {'Punctuator'}\n",
    "            elif re.search(f'{self.special_characters}', finder):\n",
    "                self.tokenization_of_expression[finder] = {'Special Character'}\n",
    "\n",
    "        print('\\nExpression after Tokenization : \\n\\n', self.tokenization_of_expression)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    lexi_obj = lexical_analyzer(\"{a -2/5*2}\")\n",
    "\n",
    "    lexi_obj.print_before_tokenization()\n",
    "\n",
    "    lexi_obj.splitFunction()\n",
    "\n",
    "    lexi_obj.tokenFinder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0f00b93d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter the Expression:3+3/6\n",
      "\n",
      "Expression : 3+3/6  \n",
      "\n",
      "\n",
      "Visting Nodes :\n",
      "\n",
      "Expression\n",
      "BinOp\n",
      "Constant\n",
      "Add\n",
      "BinOp\n",
      "Constant\n",
      "Div\n",
      "Constant\n",
      "\n",
      "Interating Fields:\n",
      "\n",
      "body <ast.BinOp object at 0x7f80268967c0>\n",
      "\n",
      "Intering child Nodes:\n",
      "\n",
      "BinOp\n",
      "\n",
      "Dump:\n",
      "\n",
      "Expression(\n",
      "    body=BinOp(\n",
      "        left=Constant(value=3),\n",
      "        op=Add(),\n",
      "        right=BinOp(\n",
      "            left=Constant(value=3),\n",
      "            op=Div(),\n",
      "            right=Constant(value=6))))\n",
      "\n",
      "Expression after Evaluation : 3.5\n"
     ]
    }
   ],
   "source": [
    "import ast\n",
    "\n",
    "# class for AST Implementation\n",
    "class as_tree:\n",
    "\n",
    "    # Constructor\n",
    "    def __init__(self):\n",
    "        self.inputExpression = None\n",
    "        self.AsTree = None\n",
    "    # function to take input from user\n",
    "    def input_equation(self):\n",
    "        self.inputExpression = input('Enter the Expression:')\n",
    "        print(f'\\nExpression : {self.inputExpression} ', '\\n')\n",
    "    # function to implement ast.parse() for tokenization\n",
    "    def tree_parser(self):\n",
    "        self.AsTree = ast.parse(self.inputExpression, mode='eval')\n",
    "    # function to visit each node recursively and print names and  keys\n",
    "    def inter_nodes(self):\n",
    "\n",
    "        print('\\nVisting Nodes :\\n')\n",
    "        for node in ast.walk(self.AsTree):\n",
    "            print(node.__class__.__name__)\n",
    "        print('\\nInterating Fields:\\n')\n",
    "        for name, value in ast.iter_fields(self.AsTree):\n",
    "            print(name, value)\n",
    "        print('\\nIntering child Nodes:\\n')\n",
    "        for node in ast.iter_child_nodes(self.AsTree):\n",
    "            print(node.__class__.__name__)\n",
    "    # function to print the tokenized elements of strings and indent mean's  indentation\n",
    "    def dump_ast(self):\n",
    "        print('\\nDump:\\n')\n",
    "        print(ast.dump(self.AsTree, indent=4))\n",
    "    # function to evaluate  the entered expression\n",
    "    def eval_astree(self):\n",
    "        print('\\nExpression after Evaluation :', eval(compile(self.AsTree, '', mode='eval')))\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    asTree = as_tree()\n",
    "    asTree.input_equation()\n",
    "    asTree.tree_parser()\n",
    "    asTree.inter_nodes()\n",
    "    asTree.dump_ast()\n",
    "    asTree.eval_astree()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
